{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 下一跳预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 准备工作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需安装如下依赖："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q torch\n",
    "# !pip install -q numpy\n",
    "# !pip install -q pandas\n",
    "# !pip install -q scikit-learn\n",
    "# !pip install -q tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 模型探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\graduation_p\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 导入所有依赖\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 固定随机种子，设置device\n",
    "seed = 3407\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'mps'  # for Apple\n",
    "torch.device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMPredictor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMPredictor, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(1, x.size(0), self.hidden_size).to(device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMPredictor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(BiLSTMPredictor, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Bi-LSTM 需要两个隐藏状态\n",
    "        h0 = torch.zeros(2, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(2, x.size(0), self.hidden_size).to(device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUPredictor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GRUPredictor, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(device)\n",
    "        out, _ = self.gru(x, h0)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSequence_(df, window_size):\n",
    "    size = len(df)\n",
    "\n",
    "    # f = df.columns.values[1:]\n",
    "\n",
    "    # 按照滑动窗口进行划分\n",
    "    seq = []\n",
    "    label = []\n",
    "    for i in range(0, size - window_size):\n",
    "        seq.append(df[i:i + window_size - 1])\n",
    "        # print(df.iloc[i + window_size - 1][f])\n",
    "        label.append(df.iloc[i + window_size - 1])\n",
    "    seq = np.array(seq).astype(float)\n",
    "    label = np.array(label).astype(float)\n",
    "    seq = torch.tensor(seq, dtype=torch.float32).to(device)\n",
    "    label = torch.tensor(label, dtype=torch.float32).to(device)\n",
    "    return seq, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 训练 & 评估定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算 RMSE（只计算点坐标和距离，不包括时间、速度等）\n",
    "def calc_rmse(predictions, targets):\n",
    "    mse = torch.mean((predictions[:, :3] - targets[:, :3]) ** 2)\n",
    "    rmse = torch.sqrt(mse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(train_X, train_Y, val_X, val_Y, model,\n",
    "               lr=1e-2, epoch_num=20, logging_steps=5):\n",
    "    # torch.cuda()\n",
    "    # 使用 DataLoader 和 TensorDataset 批量加载数据\n",
    "\n",
    "    b_size = 16\n",
    "\n",
    "    train_set = TensorDataset(train_X, train_Y)\n",
    "    train_loader = DataLoader(train_set, batch_size=b_size, shuffle=True, generator=torch.Generator(device=device))\n",
    "    test_set = TensorDataset(val_X, val_Y)\n",
    "    test_loader = DataLoader(test_set, batch_size=b_size, shuffle=False, generator=torch.Generator(device=device))\n",
    "\n",
    "    # 初始化损失函数和优化器\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    # 模型训练\n",
    "    for epoch in tqdm(range(epoch_num)):\n",
    "        loss = 0.0\n",
    "        for data in train_loader:\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss += loss.item()\n",
    "\n",
    "        # log\n",
    "        if epoch % logging_steps == (logging_steps - 1):\n",
    "            print(f\"Epoch {epoch + 1}, loss: {loss / len(train_loader):.6f}\")\n",
    "\n",
    "    # 用验证集评估\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels = data\n",
    "            outputs = model(inputs)\n",
    "            preds.append(outputs)\n",
    "    \n",
    "    preds = torch.cat(preds, dim=0)\n",
    "    loss = criterion(preds, val_Y)\n",
    "    rmse = calc_rmse(preds, val_Y)\n",
    "\n",
    "    return model, loss.item(), rmse.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 启动训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "t = torch.tensor(1)\n",
    "print(t.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/METR-LA_p.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全部可选模型\n",
    "all_model_types = [\n",
    "    LSTMPredictor,\n",
    "    BiLSTMPredictor,\n",
    "    GRUPredictor\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集：验证集：测试集 == 6:2:2\n",
    "def split_dataset_(df, window_size):\n",
    "    seq, label = createSequence_(df, window_size)\n",
    "\n",
    "    # train\n",
    "    train_seq, test_seq = train_test_split(seq, test_size=0.4, random_state=seed)\n",
    "    train_label, test_label = train_test_split(label, test_size=0.4, random_state=seed)\n",
    "\n",
    "    # val & test\n",
    "    val_seq, test_seq = train_test_split(test_seq, test_size=0.5, random_state=seed)\n",
    "    val_label, test_label = train_test_split(test_label, test_size=0.5, random_state=seed)\n",
    "\n",
    "    return train_seq, train_label, val_seq, val_label, test_seq, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 部分参数\n",
    "window_size = 10\n",
    "lr = 1e-4\n",
    "epoch_num = 200\n",
    "logging_steps = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0+cu116\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current model_type: <class '__main__.LSTMPredictor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 10/200 [00:42<12:32,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, loss: 0.257271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 20/200 [01:24<12:56,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, loss: 0.208733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 30/200 [02:07<12:09,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, loss: 0.179831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 40/200 [02:51<11:30,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, loss: 0.177920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 50/200 [03:37<11:32,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, loss: 0.096312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 60/200 [04:22<10:18,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, loss: 0.099876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 70/200 [05:07<09:41,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70, loss: 0.087590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 80/200 [05:51<08:56,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80, loss: 0.164100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 90/200 [06:38<08:39,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90, loss: 0.076729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 100/200 [07:24<07:35,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, loss: 0.171698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 110/200 [08:09<06:40,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110, loss: 0.052824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 120/200 [08:55<06:06,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120, loss: 0.114022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 130/200 [09:41<05:14,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130, loss: 0.064867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 140/200 [10:25<04:29,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140, loss: 0.072450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 150/200 [11:13<03:57,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150, loss: 0.105743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 160/200 [11:59<03:01,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160, loss: 0.056122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 170/200 [12:45<02:18,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170, loss: 0.073981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 180/200 [13:27<01:19,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180, loss: 0.060683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 190/200 [14:09<00:42,  4.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190, loss: 0.084422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [14:55<00:00,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200, loss: 0.042333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test rmse: 5.71907\n",
      "================================================================================\n",
      "\n",
      "current model_type: <class '__main__.BiLSTMPredictor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 10/200 [00:57<18:05,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, loss: 0.199114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 20/200 [01:55<17:27,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, loss: 0.173930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 30/200 [02:52<16:03,  5.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, loss: 0.157771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 40/200 [03:47<14:25,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, loss: 0.134743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 50/200 [04:41<13:29,  5.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, loss: 0.072924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 60/200 [05:37<12:50,  5.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, loss: 0.079769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 70/200 [06:32<12:42,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70, loss: 0.054989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 80/200 [07:33<11:41,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80, loss: 0.113203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 90/200 [08:30<10:31,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90, loss: 0.054994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 100/200 [09:23<08:18,  4.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, loss: 0.120506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 110/200 [10:08<06:37,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110, loss: 0.038092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 120/200 [10:52<05:53,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120, loss: 0.070803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 130/200 [11:37<05:10,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130, loss: 0.040596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 140/200 [12:21<04:22,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140, loss: 0.046534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 150/200 [13:06<03:41,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150, loss: 0.065665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 160/200 [13:51<02:56,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160, loss: 0.037773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 170/200 [14:36<02:13,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170, loss: 0.036996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 180/200 [15:20<01:28,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180, loss: 0.025229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 190/200 [16:05<00:44,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190, loss: 0.061037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [16:49<00:00,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200, loss: 0.028545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test rmse: 4.75137\n",
      "================================================================================\n",
      "\n",
      "current model_type: <class '__main__.GRUPredictor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 10/200 [00:34<10:58,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, loss: 0.229876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 20/200 [01:09<10:34,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, loss: 0.192013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 30/200 [01:45<09:58,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, loss: 0.175683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 40/200 [02:20<09:20,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, loss: 0.170545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 50/200 [02:55<08:46,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, loss: 0.092568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 60/200 [03:31<08:11,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, loss: 0.104318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 70/200 [04:06<07:36,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70, loss: 0.082700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 80/200 [04:41<07:00,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80, loss: 0.171681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 90/200 [05:16<06:25,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90, loss: 0.079906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 100/200 [05:52<05:49,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, loss: 0.176380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 110/200 [06:27<05:14,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110, loss: 0.057245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 120/200 [07:02<04:40,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120, loss: 0.121277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 130/200 [07:37<04:05,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130, loss: 0.078781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 140/200 [08:13<03:30,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140, loss: 0.088922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 150/200 [08:48<02:55,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150, loss: 0.110351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 160/200 [09:23<02:20,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160, loss: 0.066474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 170/200 [09:59<01:48,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170, loss: 0.095524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 180/200 [10:35<01:10,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180, loss: 0.065313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 190/200 [11:10<00:35,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190, loss: 0.099775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [11:46<00:00,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200, loss: 0.052344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test rmse: 6.29479\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "min_rmse = 1e+5\n",
    "\n",
    "train_seq, train_label, val_seq, val_label, test_seq, test_label = split_dataset_(df, window_size)\n",
    "    # 遍历模型\n",
    "for i in range(3):\n",
    "    if i == 0:\n",
    "        model = LSTMPredictor(train_seq.shape[2], 108, train_label.shape[1]).to(device)\n",
    "        torch.save(model.state_dict(), 'model/LSTMPredictor.pt')\n",
    "    elif i == 1:\n",
    "        model = BiLSTMPredictor(train_seq.shape[2], 108, train_label.shape[1]).to(device)\n",
    "        torch.save(model.state_dict(), 'model/BiLSTMPredictor.pt')\n",
    "    else:\n",
    "        model = GRUPredictor(train_seq.shape[2], 108, train_label.shape[1]).to(device)\n",
    "        torch.save(model.state_dict(), 'model/GRU.pt')\n",
    "            \n",
    "    print(f'current model_type: {type(model)}', flush=True)\n",
    "        \n",
    "        # 训练\n",
    "    \n",
    "    model, loss, rmse = trainModel(train_seq, train_label, val_seq, val_label, model,\n",
    "                                           lr, epoch_num, logging_steps)\n",
    "        # 在（划分的）测试集上测试\n",
    "    predictions = []\n",
    "    test_set = TensorDataset(test_seq, test_label)\n",
    "    test_loader = DataLoader(test_set, batch_size=32, shuffle=False, generator=torch.Generator(device=device))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels = data\n",
    "            outputs = model(inputs)\n",
    "            predictions.append(outputs)\n",
    "\n",
    "    predictions = torch.cat(predictions, dim=0)\n",
    "    test_rmse = calc_rmse(predictions, test_label)\n",
    "    print(f'test rmse: {test_rmse:.5f}')\n",
    "    print(f'=' * 80, end='\\n\\n', flush=True)\n",
    "\n",
    "    # 记录最好的模型\n",
    "    if test_rmse < min_rmse:\n",
    "        min_rmse = test_rmse\n",
    "        best_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model: BiLSTMPredictor(\n",
      "  (lstm): LSTM(207, 108, batch_first=True, bidirectional=True)\n",
      "  (fc): Linear(in_features=216, out_features=207, bias=True)\n",
      ")\n",
      "min_rmse: 4.751367\n"
     ]
    }
   ],
   "source": [
    "print(f'best model: {best_model}')\n",
    "print(f'min_rmse: {min_rmse:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 在真实测试集上预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>entity_id</th>\n",
       "      <th>traj_id</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>current_dis</th>\n",
       "      <th>speeds</th>\n",
       "      <th>holidays</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>355</td>\n",
       "      <td>2013-10-08T08:30:00Z</td>\n",
       "      <td>256</td>\n",
       "      <td>25</td>\n",
       "      <td>[116.324127,39.897049]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.6075</td>\n",
       "      <td>0</td>\n",
       "      <td>116.324127</td>\n",
       "      <td>39.897049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>356</td>\n",
       "      <td>2013-10-08T08:30:55Z</td>\n",
       "      <td>256</td>\n",
       "      <td>25</td>\n",
       "      <td>[116.327652,39.897018]</td>\n",
       "      <td>0.300751</td>\n",
       "      <td>21.1500</td>\n",
       "      <td>0</td>\n",
       "      <td>116.327652</td>\n",
       "      <td>39.897018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>357</td>\n",
       "      <td>2013-10-08T08:32:44Z</td>\n",
       "      <td>256</td>\n",
       "      <td>25</td>\n",
       "      <td>[116.330978,39.897041]</td>\n",
       "      <td>0.584521</td>\n",
       "      <td>20.4825</td>\n",
       "      <td>0</td>\n",
       "      <td>116.330978</td>\n",
       "      <td>39.897041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>358</td>\n",
       "      <td>2013-10-08T08:34:32Z</td>\n",
       "      <td>256</td>\n",
       "      <td>25</td>\n",
       "      <td>[116.336624,39.897305]</td>\n",
       "      <td>1.067123</td>\n",
       "      <td>20.6575</td>\n",
       "      <td>0</td>\n",
       "      <td>116.336624</td>\n",
       "      <td>39.897305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>359</td>\n",
       "      <td>2013-10-08T08:35:25Z</td>\n",
       "      <td>256</td>\n",
       "      <td>25</td>\n",
       "      <td>[116.341118,39.897537]</td>\n",
       "      <td>1.451388</td>\n",
       "      <td>24.0700</td>\n",
       "      <td>0</td>\n",
       "      <td>116.341118</td>\n",
       "      <td>39.897537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                  time  entity_id  traj_id             coordinates  \\\n",
       "0  355  2013-10-08T08:30:00Z        256       25  [116.324127,39.897049]   \n",
       "1  356  2013-10-08T08:30:55Z        256       25  [116.327652,39.897018]   \n",
       "2  357  2013-10-08T08:32:44Z        256       25  [116.330978,39.897041]   \n",
       "3  358  2013-10-08T08:34:32Z        256       25  [116.336624,39.897305]   \n",
       "4  359  2013-10-08T08:35:25Z        256       25  [116.341118,39.897537]   \n",
       "\n",
       "   current_dis   speeds  holidays   longitude   latitude  \n",
       "0     0.000000  21.6075         0  116.324127  39.897049  \n",
       "1     0.300751  21.1500         0  116.327652  39.897018  \n",
       "2     0.584521  20.4825         0  116.330978  39.897041  \n",
       "3     1.067123  20.6575         0  116.336624  39.897305  \n",
       "4     1.451388  24.0700         0  116.341118  39.897537  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_real = pd.read_csv('data/jump_task.csv')\n",
    "\n",
    "# 填充空值（便于统一读取，且采用forward fill，不会影响minmax）\n",
    "df_real['coordinates'] = df_real['coordinates'].ffill()\n",
    "df_real['current_dis'] = df_real['current_dis'].ffill()\n",
    "\n",
    "df_real[['longitude', 'latitude']] = pd.DataFrame(\n",
    "    df_real['coordinates'].apply(lambda x: eval(x)).tolist(), index=df_real.index\n",
    ")\n",
    "df_real.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, length \u001b[38;5;129;01min\u001b[39;00m traj_index_list\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      6\u001b[0m     traj_id \u001b[38;5;241m=\u001b[39m index\n\u001b[1;32m----> 7\u001b[0m     trajectory \u001b[38;5;241m=\u001b[39m df_real[(df_real[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraj_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m traj_id)][\u001b[43mbest_features\u001b[49m]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m      8\u001b[0m     traj_list\u001b[38;5;241m.\u001b[39mappend(trajectory[:\u001b[38;5;241m14\u001b[39m])\n\u001b[0;32m     10\u001b[0m traj_seq \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39marray(traj_list), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_features' is not defined"
     ]
    }
   ],
   "source": [
    "# 划分轨迹\n",
    "traj_index_list = df_real.groupby(['traj_id']).size()      # Series\n",
    "\n",
    "traj_list = []\n",
    "for index, length in traj_index_list.items():\n",
    "    traj_id = index\n",
    "    trajectory = df_real[(df_real['traj_id'] == traj_id)][best_features].values.tolist()\n",
    "    traj_list.append(trajectory[:14])\n",
    "\n",
    "traj_seq = torch.tensor(np.array(traj_list), dtype=torch.float32)\n",
    "traj_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1959, 4])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 预测\n",
    "predictions = best_model(traj_seq)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 写入新文件\n",
    "df_pred = pd.read_csv('data/jump_task.csv')\n",
    "windows_size = 15\n",
    "\n",
    "for i, pred in enumerate(predictions):\n",
    "    coordinates = f\"[{pred[0].item():.6f},{pred[1].item():.6f}]\"\n",
    "    current_dis = pred[2].item()\n",
    "    cur_line = (i + 1) * window_size - 1\n",
    "\n",
    "    df_pred.loc[cur_line, 'coordinates'] = coordinates\n",
    "    df_pred.loc[cur_line, 'current_dis'] = current_dis\n",
    "\n",
    "df_pred.to_csv('data/jump_task-pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 超参数调优"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在我们的实验中，Optuna 简洁、高效，故仅展示 Optuna 自动调优\n",
    "\n",
    "基于上面的实验结果，我们这里选取的模型特征组合是：**Bi-LSTM + holidays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'optuna'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# !pip install -q optuna\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01moptuna\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'optuna'"
     ]
    }
   ],
   "source": [
    "# !pip install -q optuna\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "df = pd.read_csv('data/traj.csv')\n",
    "\n",
    "# 1. 将时间time转为基于最早时间的偏移time_offset\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "base_time = df['time'].min()\n",
    "df['time_offset'] = (df['time'] - base_time).dt.total_seconds()\n",
    "\n",
    "# 2. 将coordinates列转换为经度和纬度两列\n",
    "df[['longitude', 'latitude']] = pd.DataFrame(df['coordinates'].apply(lambda x: eval(x)).tolist(), index=df.index)\n",
    "\n",
    "# 3. 将holidays转为float32\n",
    "df['holidays'] = df['holidays'].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和验证集 = 8:2\n",
    "features = ['longitude', 'latitude', 'current_dis', 'holidays']\n",
    "X, y = createSequence_(df, features, window_size)\n",
    "X_train, X_val = train_test_split(X, test_size=0.2, random_state=seed)\n",
    "y_train, y_val = train_test_split(y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([163064, 14, 4])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # 定义超参数搜索空间\n",
    "    hidden_size = trial.suggest_categorical('hidden_size', [32, 48, 64, 96, 108, 128])\n",
    "    lr = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n",
    "    num_epochs = trial.suggest_int('num_epochs', 20, 400)\n",
    "\n",
    "    model = BiLSTMPredictor(X_train.shape[2], hidden_size, y_train.shape[1]).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # 训练模型\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # 验证模型\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_val)\n",
    "        preds.append(outputs)\n",
    "        preds = torch.cat(preds, dim=0)\n",
    "        rmse = calc_rmse(preds, y_val)\n",
    "\n",
    "    # 以 rmse 作为目标值\n",
    "    return rmse.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='minimize')   # 目标最小化\n",
    "study.optimize(objective, n_trials=400)\n",
    "\n",
    "# 打印最佳参数和目标值\n",
    "print('Best Parameters:', study.best_params)\n",
    "print('Best Objective Value:', study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 40/200 [02:43<10:53,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, loss: 0.000146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 80/200 [05:27<08:09,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80, loss: 0.000948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 120/200 [08:11<05:27,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120, loss: 0.000337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 160/200 [10:55<02:36,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160, loss: 0.000203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [13:37<00:00,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200, loss: 0.000248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 部分参数\n",
    "window_size = 15\n",
    "lr = 1e-2\n",
    "epoch_num = 200\n",
    "logging_steps = 40\n",
    "\n",
    "features = ['longitude', 'latitude', 'current_dis', 'holidays']\n",
    "X, y = createSequence_(df, window_size)\n",
    "model = BiLSTMPredictor(X.shape[2], 108, y.shape[1]).to(device)\n",
    "\n",
    "train_set = TensorDataset(X, y)\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True, generator=torch.Generator(device=device))\n",
    "\n",
    "# 初始化损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "# 模型训练\n",
    "for epoch in tqdm(range(epoch_num)):\n",
    "    loss = 0.0\n",
    "    for data in train_loader:\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss += loss.item()\n",
    "\n",
    "    # log\n",
    "    if epoch % logging_steps == (logging_steps - 1):\n",
    "        print(f\"Epoch {epoch + 1}, loss: {loss / len(train_loader):.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
